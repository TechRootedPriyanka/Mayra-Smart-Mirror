{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import speech_recognition as sr # recognise speech\n",
    "import playsound # to play an audio file\n",
    "from gtts import gTTS # google text to speech\n",
    "import random\n",
    "from time import ctime # get time details\n",
    "import webbrowser # open browser\n",
    "import ssl\n",
    "import certifi\n",
    "import time\n",
    "import os # to remove created audio files\n",
    "from PIL import Image\n",
    "import subprocess\n",
    "import pyautogui #screenshot\n",
    "import pyttsx3\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import requests\n",
    "#from playsound import playsound\n",
    "\n",
    "###################### EMOTION #######################\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import image\n",
    "\n",
    "\n",
    "def emotion():\n",
    "    #load model\n",
    "    model = model_from_json(open(\"fer.json\", \"r\").read())\n",
    "    #load weights\n",
    "    model.load_weights('fer.h5')\n",
    "    face_haar_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    cap=cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        ret,test_img=cap.read()# captures frame and returns boolean value and captured image\n",
    "        if not ret:\n",
    "            continue\n",
    "        gray_img= cv2.cvtColor(test_img, cv2.COLOR_BGR2GRAY)\n",
    "        faces_detected = face_haar_cascade.detectMultiScale(gray_img, 1.32, 5)\n",
    "        for (x,y,w,h) in faces_detected:\n",
    "            cv2.rectangle(test_img,(x,y),(x+w,y+h),(255,0,0),thickness=7)\n",
    "            roi_gray=gray_img[y:y+w,x:x+h]#cropping region of interest i.e. face area from  image\n",
    "            roi_gray=cv2.resize(roi_gray,(48,48))\n",
    "            img_pixels = image.img_to_array(roi_gray)\n",
    "            img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "            img_pixels /= 255\n",
    "\n",
    "            predictions = model.predict(img_pixels)\n",
    "\n",
    "            #find max indexed array\n",
    "            max_index = np.argmax(predictions[0])\n",
    "            emotions = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "            predicted_emotion = emotions[max_index]\n",
    "            cv2.putText(test_img, predicted_emotion, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "        resized_img = cv2.resize(test_img, (1000, 700))\n",
    "        cv2.imshow('Facial emotion analysis ',resized_img)\n",
    "        if cv2.waitKey(10) == ord('q'):#wait until 'q' key is pressed\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows\n",
    "    \n",
    "\n",
    "###################### EMOTION END #######################\n",
    "###################### FACE REC #######################\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def facerec():\n",
    "    path = 'imagerec'\n",
    "    images = []\n",
    "    classname = []\n",
    "    myList = os.listdir(path)\n",
    "    #print(myList)\n",
    "    for cl in myList:\n",
    "        curimg = cv2.imread(f'{path}/{cl}')\n",
    "        images.append(curimg)\n",
    "        classname.append(os.path.splitext(cl)[0])\n",
    "    #print(classname)\n",
    "    def findEncodings(images):\n",
    "        encodeList = []\n",
    "        for img in images:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            encode = face_recognition.face_encodings(img)[0]\n",
    "            encodeList.append(encode)\n",
    "        return encodeList\n",
    "    encodeListKnown = findEncodings(images)\n",
    "    #print('EC')\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "        imgS = cv2.resize(img,(0,0),None,0.25,0.25)\n",
    "        imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "        facesCurFrame = face_recognition.face_locations(imgS)\n",
    "        encodesCurFrame = face_recognition.face_encodings(imgS, facesCurFrame)\n",
    "        for encodeFace, faceLoc in zip(encodesCurFrame, facesCurFrame):\n",
    "            matchs = face_recognition.compare_faces(encodeListKnown,encodeFace)\n",
    "            faceDis = face_recognition.face_distance(encodeListKnown,encodeFace)\n",
    "            print(faceDis)\n",
    "            matchIndex = np.argmin(faceDis)\n",
    "            if matchs[matchIndex]:\n",
    "                name = classname[matchIndex].upper()\n",
    "                print(name)      \n",
    "    cv2.imshow('webcam',img)\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "\n",
    "#############################################\n",
    "class person:\n",
    "    name = ''\n",
    "    def setName(self, name):\n",
    "        self.name = name\n",
    "\n",
    "class asis:\n",
    "    name = ''\n",
    "    def setName(self, name):\n",
    "        self.name = name\n",
    "        \n",
    "def there_exists(terms):\n",
    "    for term in terms:\n",
    "        if term in voice_data:\n",
    "            return True\n",
    "\n",
    "def engine_speak(text):\n",
    "    text = str(text)\n",
    "    engine.say(text)\n",
    "    engine.runAndWait()\n",
    "\n",
    "r = sr.Recognizer() # initialise a recogniser\n",
    "# listen for audio and convert it to text:\n",
    "def record_audio(ask=\"\"):\n",
    "    with sr.Microphone() as source: # microphone as source\n",
    "        if ask:\n",
    "            engine_speak(ask)\n",
    "        audio = r.listen(source)  #  (source, 5, 5)   listen for the audio via source\n",
    "        print(\"Done Listening\")\n",
    "        voice_data = ''\n",
    "        try:\n",
    "            voice_data = r.recognize_google(audio)  # convert audio to text\n",
    "        except sr.UnknownValueError: # error: recognizer does not understand\n",
    "            engine_speak('I did not get that')\n",
    "        except sr.RequestError:\n",
    "            engine_speak('Sorry, the service is down') # error: recognizer is not connected\n",
    "        print(\">>\", voice_data.lower()) # print what user said\n",
    "        return voice_data.lower()\n",
    "\n",
    "# get string and make a audio file to be played\n",
    "def engine_speak(audio_string):\n",
    "    audio_string = str(audio_string)\n",
    "    tts = gTTS(text=audio_string, lang='en') # text to speech(voice)\n",
    "    r = random.randint(1,20000000)\n",
    "    audio_file = 'audio' + str(r) + '.mp3'\n",
    "    tts.save(audio_file) # save as mp3\n",
    "    playsound.playsound(audio_file) # play the audio file\n",
    "    print(asis_obj.name + \":\", audio_string) # print what app said\n",
    "    os.remove(audio_file) # remove audio file\n",
    "\n",
    "def respond(voice_data):\n",
    "       # 1: greeting\n",
    "    if there_exists(['hey','hi','hello','hay','heyaa','hey mira','hey myra','hey mayra','hey you','hai']):\n",
    "        greetings = [\"hey\" + person_obj.name, \"hi\" + person_obj.name, \"I'm listening\" + person_obj.name, \"yes\" + person_obj.name, \"hello\" + person_obj.name]\n",
    "        greet = greetings[random.randint(0,len(greetings)-1)]\n",
    "        engine_speak(greet)\n",
    "\n",
    "        \n",
    "    # 2: name\n",
    "    if there_exists([\"what is your name\",\"what's your name\",\"tell me your name\"]):\n",
    "        if person_obj.name:\n",
    "            engine_speak(f\"My name is {asis_obj.name}\") #gets users name from voice input\n",
    "        else:\n",
    "            engine_speak(f\"My name is {asis_obj.name}. as if you don't know\") #incase you haven't provided your name.\n",
    "            \n",
    "    \n",
    "    if there_exists([\"give your intro\",\"introduce yourself\",\"give your introduction\",\"introduce your self\",\"give your introduction to mam\",\"give your introduction to sir\",]):\n",
    "        engine_speak(f\"My name is {asis_obj.name}, I am bot, developed by Priyanka, as per my knowledge I am coded with python, and currently i stay on a Mirror, but my permanent residency is your Heart.   \") #gets users name from voice input\n",
    "       \n",
    "    if there_exists([\"what is my name\",\"with whom you are talking\",\"who am I?\",\"mira what is my name?\",\"what is my name?\"]):\n",
    "        engine_speak(\"Your name is \" + person_obj.name + \"My Developer\")\n",
    "    \n",
    "    \n",
    "    # 3: greeting\n",
    "    if there_exists([\"how are you\",\"how are you doing\",'whats up?']):\n",
    "        engine_speak(\"I'm very well, thanks for asking \" + person_obj.name + \"How are you Doing?\")\n",
    "    \n",
    "    if there_exists([\"i am doing great\",\"I am good\",\"Good\",\"Nice\",\"I am doing fine\"]):\n",
    "        engine_speak(\"glad to know\" + person_obj.name + \"How was your day at work?\")\n",
    "    \n",
    "    if there_exists([\"work is great\",\"work is good\",\"Good\",\"work is Nice\",\"work is fine\"]):\n",
    "        engine_speak(\"Awesome, is your boss still bad?\")\n",
    "        \n",
    "    if there_exists([\"he can never change\",\"yes still bad\"]):\n",
    "        engine_speak(\"boss will be boss, let him go, will you like to play a game, or i can tell you a joke or maybe some music, What do you say?\")\n",
    "\n",
    "    if there_exists([\"i love you\"]):\n",
    "        engine_speak(\"I love you more\")\n",
    "    \n",
    "    if there_exists([\"you are so sweet\"]):\n",
    "        engine_speak(\"I know, Thanks by the way\")\n",
    "        \n",
    "        \n",
    "    if there_exists([\"you are cute\"]):\n",
    "        engine_speak(\"look at your self, you are the cute one\")\n",
    "    \n",
    "    \n",
    "    if there_exists([\"just shut up\",\"shut up\"]):\n",
    "        engine_speak(\"ok i will shut up\")\n",
    "    \n",
    "    \n",
    "        \n",
    "    # 4: time\n",
    "    if there_exists([\"what's the time\",\"tell me the time\",\"what time is it\",\"what is the time\"]):\n",
    "        time = ctime().split(\" \")[3].split(\":\")[0:2]\n",
    "        if time[0] == \"00\":\n",
    "            hours = '12'\n",
    "        else:\n",
    "            hours = time[0]\n",
    "        minutes = time[1]\n",
    "        time = hours + \" hours and \" + minutes + \"minutes\"\n",
    "        engine_speak(time)\n",
    "\n",
    " # 5: music\n",
    "    if there_exists([\"play my favourite song\",\"play my most played song\",\"mira play my most played song\"]):\n",
    "        engine_speak(\"sure\")\n",
    "        playsound('priyankasong.mp3')\n",
    "        \n",
    "    if there_exists([\"sing a song\",\"mira sing a song\",\"sing song\"]):\n",
    "        engine_speak(\"i am not at all a good singer, please dont make me sing. please\")\n",
    "        \n",
    "    if there_exists([\"just one song\"]):\n",
    "        engine_speak(\"ok i will sing, laa laa laalaare, laa laa laalaare, la la la re, laa laa laalaare, laa laa laalaare. \")\n",
    "     \n",
    "        \n",
    "    if there_exists([\"i will never ask you to sing\"]):\n",
    "        engine_speak(\"yes please, i told you\")\n",
    "               \n",
    "        \n",
    "        \n",
    "     #10 stone paper scisorrs'one more \n",
    "    if there_exists([\"maybe stone game\",\"play stone game\",\"one more time\",\"one more game\",\"play again\"]):\n",
    "        voice_data = record_audio(\"choose among rock paper or scissor\")\n",
    "        moves=[\"rock\", \"paper\", \"scissor\"]\n",
    "    \n",
    "        cmove=random.choice(moves)\n",
    "        pmove=voice_data\n",
    "        \n",
    "\n",
    "        engine_speak(\"I chose, \" + cmove)\n",
    "        #engine_speak(\"You chose \" + pmove)\n",
    "        #engine_speak(\"hi\")\n",
    "        if pmove==cmove:\n",
    "            engine_speak(\"the match is draw\")\n",
    "        elif pmove== \"rock\" and cmove== \"scissor\":\n",
    "            engine_speak(\"You win, poor me.\")\n",
    "        elif pmove== \"rock\" and cmove== \"paper\":\n",
    "            engine_speak(\"I win, I am smart\")\n",
    "        elif pmove== \"paper\" and cmove== \"rock\":\n",
    "            engine_speak(\"You win, Awesome\")\n",
    "        elif pmove== \"paper\" and cmove== \"scissor\":\n",
    "            engine_speak(\"I win, I win\")\n",
    "        elif pmove== \"scissor\" and cmove== \"paper\":\n",
    "            engine_speak(\"You win, Congo\")\n",
    "        elif pmove== \"scissor\" and cmove== \"rock\":\n",
    "            engine_speak(\"I win, \")\n",
    "\n",
    "     #11 toss a coin\n",
    "    if there_exists([\"i dont know what to do, can you help\"]):\n",
    "        engine_speak(\"when you dont know what to do just toss, you want me to toss for you?\")\n",
    "    \n",
    "    if there_exists([\"ok toss\",\"yes toss\",\"ok flip a coin\",\"coin\"]):\n",
    "        moves=[\"head\", \"tails\"]   \n",
    "        cmove=random.choice(moves)\n",
    "        engine_speak(\"its \" + cmove + \"was it helpful?\")\n",
    "\n",
    "        \n",
    "    if there_exists([\"exit\", \"quit\", \"goodbye\"]):\n",
    "        engine_speak(\"bye\")\n",
    "        exit()\n",
    "\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "person_obj = person()\n",
    "asis_obj = asis()\n",
    "asis_obj.name = 'mayra'\n",
    "person_obj.name = 'Priyanka'\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "\n",
    "while(1):\n",
    "    voice_data = record_audio(\"Recording\") # get the voice input\n",
    "    print(\"Done\")\n",
    "    print(\"Q:\", voice_data)\n",
    "    respond(voice_data) # respond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
